"""
Author: Nicole Wang
Date: Updated June 2025

This script builds a conversational chatbot using LangChain with an open-source Hugging Face LLM and memory to track ongoing dialogue context.
"""

from langchain.llms import HuggingFacePipeline
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

# --------------------------
# Load Pre-trained Model
# --------------------------

model_name = "google/flan-t5-base"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

pipe = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=256,
    temperature=0.7,
    top_p=0.9
)

llm = HuggingFacePipeline(pipeline=pipe)

# --------------------------
# Set Up Memory & Chain
# --------------------------

memory = ConversationBufferMemory()
conversation = ConversationChain(llm=llm, memory=memory, verbose=False)

# --------------------------
# Chat Loop
# --------------------------

print("Therapy Chatbot (type 'exit' to quit)")
print("--------------------------------------")
while True:
    user_input = input("You: ")
    if user_input.lower() in ["exit", "quit", "bye"]:
        print("Bot: It was nice talking to you. Take care!")
        break
    response = conversation.predict(input=user_input)
    print("Bot:", response)
